---
title: 'Google Data Analytics Capstone: Cyclistic Bike-Share Analysis Case Study'
author: "Trang Vu"
date: "09/11/2021"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---

This is a case study for the **Google Data Analytics Professional Certificate.** The project provides the Cyclistic Datasets for the learners to follow the steps of data analysis process: **ask, prepare, process, analyze, share and act** in order to answer the key business problems.  

# Phrase 1: Ask
In this phase, I need to do two things. I define the problem to be solved and I make sure that I fully understand stakeholder expectations.

### About the company
The direct of the marking team Lily Moreno believes that maximizing the number of annual members will
be key to future growth. Rather than creating a marketing campaign that targets all-new customers, Moreno believes there is a
very good chance to convert casual riders into members. 
Moreno has set a clear goal: Design marketing strategies aimed at converting casual riders into annual members.

###Business Task
Analyze the most recent 12 month Cyclistic Customer Data **(from 10/2020 to 09/2021)** in order to ansIr the key questions:

1. How do annual members and casual riders use Cyclistic bikes differently?
2. Why would casual riders buy Cyclistic annual memberships?
3. How can Cyclistic use digital media to influence casual riders to become members?

### Key Stakeholders:
Cyclistic executive team, Lily Moreno: The director of marketing and my manager.

# Phrase 2: Prepare
This is where the data analysts collect and store data so later I will use for the upcoming analysis process. In this phrase, I will learn more about the different types of data and how to identify which kinds of data are most useful for solving a particular problem. 

### Import libraries
```{r}
#helps wrangle data
library(tidyverse)  
#helps wrangle date attributes
library(lubridate)  
#helps visualize data
library(ggplot2)  
```

## Step 1: Load datasets
Upload Divvy datasets (csv files) here.
```{r}
d10_2020 <- read_csv("202010-divvy-tripdata.csv")
d11_2020 <- read_csv("202011-divvy-tripdata.csv")
d12_2020 <- read_csv("202012-divvy-tripdata.csv")
d01_2021 <- read_csv("202101-divvy-tripdata.csv")
d02_2021 <- read_csv("202102-divvy-tripdata.csv")
d03_2021 <- read_csv("202103-divvy-tripdata.csv")
d04_2021 <- read_csv("202104-divvy-tripdata.csv")
d05_2021 <- read_csv("202105-divvy-tripdata.csv")
d06_2021 <- read_csv("202106-divvy-tripdata.csv")
d07_2021 <- read_csv("202107-divvy-tripdata.csv")
d08_2021 <- read_csv("202108-divvy-tripdata.csv")
d09_2021 <- read_csv("202109-divvy-tripdata.csv")
```

## Step 2: Wrangle data and combine into a single file
### Compare column names each of the files
As all names are already consistent - they do not need to be renamed. 
```{r}
colnames(d10_2020)
colnames(d11_2020)
colnames(d12_2020)
colnames(d01_2021)
colnames(d02_2021)
colnames(d03_2021)
colnames(d04_2021)
colnames(d05_2021)
colnames(d06_2021)
colnames(d07_2021)
colnames(d08_2021)
colnames(d09_2021)
```

### Inspect the dataframes and look for incongruencies

```{r}
str(d10_2020)
str(d11_2020)
str(d12_2020)
str(d01_2021)
str(d02_2021)
str(d03_2021)
str(d04_2021)
str(d05_2021)
str(d06_2021)
str(d07_2021)
str(d08_2021)
str(d09_2021)
```

### Inspect the dataframes and look for incongruencies
After the above comparison, I need to convert **start_station_id** to character so I can perform calculations correctly later on.

```{r}
d10_2020 <-  mutate(d10_2020, start_station_id = as.character(start_station_id) 
                            ,end_station_id = as.character(end_station_id))
d11_2020 <-  mutate(d11_2020, start_station_id = as.character(start_station_id)
                            ,end_station_id = as.character(end_station_id))
```

### Stack individual quarter's data frames into one big data frame

```{r}
all_trips <- bind_rows(d10_2020, d11_2020, d12_2020, d01_2021, d02_2021, d03_2021, d04_2021, d05_2021, d06_2021, d07_2021, d08_2021, d09_2021)
```

### Remove start_lat, start_lng, end_lat, end_lng fields as this data was dropped beginning in 2020

```{r}
all_trips <- all_trips %>%  
  select(-c(start_lat,start_lng,end_lat,end_lng))
colnames(all_trips)
```
# Phrase 3: Process
A process known as data cleaning is the fixing or removing incorrect, corrupted, incorrectly formatted, duplicate, or incomplete data within a dataset. What I aim to achieve is clean data. 

## Step 3: Clean up and add data to prepare for analysis 

### Inspect the new table that has been created
```{r}
#List of column names
colnames(all_trips) 
#How many rows are in data frame?
nrow(all_trips)  
#Dimensions of the data frame?
dim(all_trips) 
#See the first 6 rows of data frame.  Also tail(all_trips)
head(all_trips)  
#See list of columns and data types (numeric, character, etc)
str(all_trips)  
#Statistical summary of data. Mainly for numberics
summary(all_trips)  
```

### Remove inconsistency
There are four unique values in member_casual subscriber, member, customer, casual but 2020 on wards these member has been changed into two unique values that are member, casual.

```{r}
table(all_trips$member_casual)
all_trips <-  all_trips %>% 
  mutate(member_casual = recode(member_casual
                                ,"Subscriber" = "member"
                                ,"Customer" = "Casual"))
table(all_trips$member_casual)
```
### Day (Add new columns)
Add columns that list the date, month, day, and year of each ride. This will allow us to aggregate ride data for each month, day, or year ... before completing these operations I could only aggregate at the ride level.

```{r}
#The default format is yyyy-mm-dd
all_trips$date <- as.Date(all_trips$started_at) 
all_trips$month <- format(as.Date(all_trips$date), "%m")
all_trips$day <- format(as.Date(all_trips$date), "%d")
all_trips$year <- format(as.Date(all_trips$date), "%Y")
all_trips$day_of_Iek <- format(as.Date(all_trips$date), "%A")
```

### Ride length (Add new column)
**ride_length** is the distance betIen started time and ended time.

```{r}
# Add a "ride_length" calculation to all_trips (in minutes)
all_trips$ride_length <- difftime(all_trips$ended_at,all_trips$started_at,units = "mins")
head(all_trips$ride_length)
# Inspect the structure of the columns
str(all_trips)
# Convert "ride_length" from Factor to numeric so I can run calculations on the data
is.factor(all_trips$ride_length)
all_trips$ride_length <- as.numeric(as.character(all_trips$ride_length))
is.numeric(all_trips$ride_length)
# Remove "bad" data
# The dataframe includes a few hundred entries when bikes Ire taken out of docks and checked for quality by Divvy or ride_length was negative
# I will create a new version of the dataframe (v2) since data is being removed
all_trips_v2 <- all_trips[!(all_trips$start_station_name == "HQ QR" | all_trips$ride_length<0),]
```
### Remove NA 
Remove the missing values in the dataset. 
```{r}
#Check the missing values in the dataset.
colSums(is.na(all_trips_v2))
#Remove NA
all_trips_v3 <- all_trips_v2[!(is.na(all_trips_v2$start_station_id) | is.na(all_trips_v2$end_station_id) | is.na(all_trips_v2$member_casual) | is.na(all_trips_v2$end_station_name)),]
table(all_trips_v3$member_casual)
#Check again for the missing values in the dataset.
colSums(is.na(all_trips_v3))
```
# Phrase 4: Analyze
Analyzing the data I've collected involves using tools to transform and organize that information so that I can draw useful conclusions, make predictions, and drive informed decision-making. 

### Conduct Descriptive analysis
Firstly, I need to look at the basic descriptive statistics of the data. 
```{r}
# Statistic summary of ride length in minutes
summary(all_trips_v3$ride_length) 
# Compare members and casual users
aggregate(all_trips_v3$ride_length ~ all_trips_v3$member_casual, FUN = mean)
aggregate(all_trips_v3$ride_length ~ all_trips_v3$member_casual, FUN = median)
aggregate(all_trips_v3$ride_length ~ all_trips_v3$member_casual, FUN = max)
aggregate(all_trips_v3$ride_length ~ all_trips_v3$member_casual, FUN = min)
```

Notice that the days of the week are out of order. Let's fix that.
```{r}
all_trips_v3$day_of_Iek <- ordered(all_trips_v3$day_of_Iek, levels=c("Sunday", "Monday", "Tuesday", "Idnesday", "Thursday", "Friday", "Saturday"))
```

Now, let's run the average ride time by each day for members vs casual users.

```{r}
aggregate(all_trips_v3$ride_length ~ all_trips_v3$member_casual + all_trips_v3$day_of_Iek, FUN = mean)
```

The I will look at the total number of rides and the average ride duration (in seconds) by weekday for casual customers and members.

```{r}
# analyze ridership data by type and Iekday
all_trips_v3 %>% 
#creates Iekday field using wday()
  mutate(Iekday = wday(started_at, label = TRUE)) %>%
#groups by usertype and Iekday
  group_by(member_casual, Iekday) %>% 
#calculates the number of rides and average duration 
  summarise(number_of_rides = n()	
#calculates the average duration
  ,average_duration = mean(ride_length)) %>% 
#sorts
  arrange(member_casual, Iekday)

```
# Phrase 5: Share
Here I learn how data analysts interpret results and share them with others to help stakeholders make effective data-driven decisions. In the share phase, visualization is a data analyst's best friend. 

### Visualization 1: Total number of rides by rider type
Let's visualize the number of rides by rider type.

```{r}
all_trips_v3 %>% 
  mutate(Iekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, Iekday) %>% 
  summarise(number_of_rides = n(),average_duration = mean(ride_length)) %>%           
  arrange(member_casual, Iekday)  %>% 
  ggplot(aes(x = Iekday, y = number_of_rides, fill = member_casual)) + geom_col(position = "dodge") +
  scale_fill_manual("Member_casual",values = c('#00D1F8', '#F8EF00'))+
  ggtitle( "Number Of Rides By Rider Type")
```

### Visualization 2: Average Cyclistic Bike-Share Rides
Let's create a visualization for average duration.

```{r}
  all_trips_v3 %>% 
    mutate(Iekday = wday(started_at, label = TRUE)) %>% 
    group_by(member_casual, Iekday) %>% 
    summarise(number_of_rides = n()
              ,average_duration = mean(ride_length)) %>% 
    arrange(member_casual, Iekday)  %>% 
    ggplot(aes(x = Iekday, y = average_duration, fill = member_casual)) +
    geom_col(position = "dodge")+
    scale_fill_manual("Member_casual",values = c('#00D1F8', '#F8EF00'))+
    ggtitle( "Average Cyclistic Bike-Share Rides")
```

## Export summary file for further analysis
Exported the data as a csv file.
```{r}
  # Create a csv file that I will visualize in Excel, Tableau, or my presentation software
  counts <- aggregate(all_trips_v3$ride_length ~ all_trips_v3$member_casual + all_trips_v3$day_of_Iek, FUN = mean)
  write.csv(counts, file = 'avg_ride_length.csv')
```

# Phrase 6: ACT
Now, I know the problem, Let's solve it!
This is the phase where I need carefully go through our data problem and the analysis I made to make a data-driven decision.

### Key Findings
Based on the "Number of Rides By Rider Type" graph, we can see that members usually use bike on weekdays while the casual members mostly use bike during their weekend. It can be explained that the members use bike to commute to work on the daily basic while the casual members just just bike for their leisure on the weekend. 

According to the "Average Cyclistic Bike-Share Rides" graph, we also see that casual members usually use bike for a longer period of time while members consistently use bike for a shorter time.

### Recommendations
1. Charge higher price for non-members during the weekends in order to encourage the casual members to sign up for membership. 
2. Change the pricing system as follows:
* Limiting the hours for the non-members during weekends.
* Allow annual members to use bike for the higher duration compared to the non-members.

By following these recommendations, the Cyclistic can convert more casual members into the annual members. 



